{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f98c2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully!\n",
      "  - Pandas version: 2.3.3\n",
      "  - NumPy version: 2.4.0\n",
      "  - XGBoost version: 3.1.2\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 1: IMPORT LIBRARIES\n",
    "# ============================================================================\n",
    "# Run this cell first to import all required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, \n",
    "                            ConfusionMatrixDisplay, roc_curve, auc,\n",
    "                            f1_score, recall_score, precision_score, roc_auc_score)\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")\n",
    "print(f\"  - Pandas version: {pd.__version__}\")\n",
    "print(f\"  - NumPy version: {np.__version__}\")\n",
    "print(f\"  - XGBoost version: {xgb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85ad0c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration set!\n",
      "  - Data path: heart.csv\n",
      "  - Number of monkeys: 30\n",
      "  - Number of iterations: 20\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: CONFIGURE PATHS AND PARAMETERS\n",
    "# ============================================================================\n",
    "# Update the DATA_PATH to point to your CSV file\n",
    "\n",
    "# UPDATE THIS PATH TO YOUR CSV FILE LOCATION:\n",
    "DATA_PATH = 'heart.csv'  # or 'heart_disease_data01.csv'\n",
    "\n",
    "# For Windows: DATA_PATH = r'C:\\Users\\YourName\\Documents\\heart.csv'\n",
    "# For Mac/Linux: DATA_PATH = '/home/username/Documents/heart.csv'\n",
    "\n",
    "# SMO Parameters\n",
    "N_MONKEYS = 30\n",
    "N_ITERATIONS = 20  # Start with 20 for testing, increase to 100 for final run\n",
    "\n",
    "# Hyperparameter bounds\n",
    "bounds = np.array([\n",
    "    [10, 100],    # rf_n_estimators\n",
    "    [1, 20],      # rf_max_depth\n",
    "    [10, 100],    # xgb_n_estimators\n",
    "    [1, 20],      # xgb_max_depth\n",
    "    [0.01, 0.3],  # xgb_learning_rate\n",
    "    [2, 50]       # rf_min_samples_split\n",
    "])\n",
    "\n",
    "print(\"✓ Configuration set!\")\n",
    "print(f\"  - Data path: {DATA_PATH}\")\n",
    "print(f\"  - Number of monkeys: {N_MONKEYS}\")\n",
    "print(f\"  - Number of iterations: {N_ITERATIONS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1390e23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "--------------------------------------------------------------------------------\n",
      "✓ File has headers, loading with headers...\n",
      "✓ Data loaded successfully!\n",
      "  - Shape: (303, 14)\n",
      "  - Columns: ['age', 'sex', 'chest_pain_type', 'resting_bp', 'cholestoral', 'fasting_blood_sugar', 'restecg', 'max_hr', 'exang', 'oldpeak', 'slope', 'num_major_vessels', 'thal', 'target']\n",
      "\n",
      "First 5 rows:\n",
      "   age  sex  chest_pain_type  resting_bp  cholestoral  fasting_blood_sugar  \\\n",
      "0   63    1                3         145          233                    1   \n",
      "1   37    1                2         130          250                    0   \n",
      "2   41    0                1         130          204                    0   \n",
      "3   56    1                1         120          236                    0   \n",
      "4   57    0                0         120          354                    0   \n",
      "\n",
      "   restecg  max_hr  exang  oldpeak  slope  num_major_vessels  thal  target  \n",
      "0        0     150      0      2.3      0                  0     1       1  \n",
      "1        1     187      0      3.5      0                  0     2       1  \n",
      "2        0     172      0      1.4      2                  0     2       1  \n",
      "3        1     178      0      0.8      2                  0     2       1  \n",
      "4        1     163      1      0.6      2                  0     2       1  \n",
      "\n",
      "Data types:\n",
      "age                      int64\n",
      "sex                      int64\n",
      "chest_pain_type          int64\n",
      "resting_bp               int64\n",
      "cholestoral              int64\n",
      "fasting_blood_sugar      int64\n",
      "restecg                  int64\n",
      "max_hr                   int64\n",
      "exang                    int64\n",
      "oldpeak                float64\n",
      "slope                    int64\n",
      "num_major_vessels        int64\n",
      "thal                     int64\n",
      "target                   int64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "age                    0\n",
      "sex                    0\n",
      "chest_pain_type        0\n",
      "resting_bp             0\n",
      "cholestoral            0\n",
      "fasting_blood_sugar    0\n",
      "restecg                0\n",
      "max_hr                 0\n",
      "exang                  0\n",
      "oldpeak                0\n",
      "slope                  0\n",
      "num_major_vessels      0\n",
      "thal                   0\n",
      "target                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: LOAD AND PREVIEW DATA\n",
    "# ============================================================================\n",
    "# Load the dataset and check if it's loaded correctly\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "column_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', \n",
    "               'restecg', 'thalach', 'exang', 'oldpeak', 'slope', \n",
    "               'ca', 'thal', 'target']\n",
    "\n",
    "try:\n",
    "    # Try loading with headers first\n",
    "    data_test = pd.read_csv(DATA_PATH, nrows=5)\n",
    "    \n",
    "    # Check if file has headers\n",
    "    if 'target' in data_test.columns or 'age' in data_test.columns:\n",
    "        print(\"✓ File has headers, loading with headers...\")\n",
    "        data = pd.read_csv(DATA_PATH)\n",
    "    else:\n",
    "        print(\"✓ File has no headers, loading with custom column names...\")\n",
    "        data = pd.read_csv(DATA_PATH, header=None, names=column_names)\n",
    "    \n",
    "    print(f\"✓ Data loaded successfully!\")\n",
    "    print(f\"  - Shape: {data.shape}\")\n",
    "    print(f\"  - Columns: {list(data.columns)}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(data.head())\n",
    "    \n",
    "    print(\"\\nData types:\")\n",
    "    print(data.dtypes)\n",
    "    \n",
    "    print(\"\\nMissing values:\")\n",
    "    print(data.isnull().sum())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"✗ ERROR: File not found at '{DATA_PATH}'\")\n",
    "    print(\"Please check the file path and try again.\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ ERROR: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b72bc1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing data...\n",
      "--------------------------------------------------------------------------------\n",
      "Before dropping NaN - Shape: (303, 14)\n",
      "After dropping NaN - Shape: (303, 14)\n",
      "\n",
      "Target distribution:\n",
      "target\n",
      "1    165\n",
      "0    138\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns to encode: ['sex', 'restecg', 'exang', 'slope', 'thal']\n",
      "After encoding - Shape: (303, 18)\n",
      "Final columns: ['age', 'chest_pain_type', 'resting_bp', 'cholestoral', 'fasting_blood_sugar', 'max_hr', 'oldpeak', 'num_major_vessels', 'target', 'sex_1', 'restecg_1', 'restecg_2', 'exang_1', 'slope_1', 'slope_2', 'thal_1', 'thal_2', 'thal_3']\n",
      "\n",
      "✓ Preprocessing complete!\n",
      "  - Features shape: (303, 17)\n",
      "  - Target shape: (303,)\n",
      "  - Class distribution: {1: 165, 0: 138}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: DATA PREPROCESSING\n",
    "# ============================================================================\n",
    "# Clean and prepare the data\n",
    "\n",
    "print(\"\\nPreprocessing data...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Replace '?' with NaN\n",
    "data.replace('?', pd.NA, inplace=True)\n",
    "\n",
    "# Convert all columns to numeric\n",
    "for col in data.columns:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "print(f\"Before dropping NaN - Shape: {data.shape}\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "print(f\"After dropping NaN - Shape: {data.shape}\")\n",
    "\n",
    "# Check target distribution\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(data['target'].value_counts())\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "categorical_columns = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "\n",
    "# Only encode columns that exist in the dataset\n",
    "categorical_columns = [col for col in categorical_columns if col in data.columns]\n",
    "\n",
    "print(f\"\\nCategorical columns to encode: {categorical_columns}\")\n",
    "\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "print(f\"After encoding - Shape: {data.shape}\")\n",
    "print(f\"Final columns: {list(data.columns)}\")\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "print(f\"\\n✓ Preprocessing complete!\")\n",
    "print(f\"  - Features shape: {X.shape}\")\n",
    "print(f\"  - Target shape: {y.shape}\")\n",
    "print(f\"  - Class distribution: {y.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eb3af8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data...\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Data split complete!\n",
      "  - Training set: 212 samples\n",
      "  - Test set: 91 samples\n",
      "  - Number of features: 17\n",
      "\n",
      "Training set class distribution:\n",
      "target\n",
      "1    115\n",
      "0     97\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set class distribution:\n",
      "target\n",
      "1    50\n",
      "0    41\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: TRAIN-TEST SPLIT\n",
    "# ============================================================================\n",
    "# Split data into training and testing sets\n",
    "\n",
    "print(\"\\nSplitting data...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"✓ Data split complete!\")\n",
    "print(f\"  - Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"  - Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"  - Number of features: {X_train.shape[1]}\")\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5580ca3a",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    " ============================================================================\n",
    "# CELL 6: DEFINE SPIDER MONKEY CLASS AND FUNCTIONS\n",
    "# ============================================================================\n",
    "# Define all the functions needed for SMO\n",
    "\n",
    "print(\"\\nDefining Spider Monkey Optimization functions...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "class SpiderMonkey:\n",
    "    \"\"\"Represents a spider monkey with position and fitness.\"\"\"\n",
    "    def __init__(self, position, fitness):\n",
    "        self.position = position\n",
    "        self.fitness = fitness\n",
    "\n",
    "print(\"✓ SpiderMonkey class defined\")\n",
    "\n",
    "def evaluate_fitness(position, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate fitness of a position (hyperparameter combination).\n",
    "    Returns negative accuracy for minimization.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Decode position to hyperparameters\n",
    "        rf_n_estimators = int(position[0])\n",
    "        rf_max_depth = int(position[1])\n",
    "        xgb_n_estimators = int(position[2])\n",
    "        xgb_max_depth = int(position[3])\n",
    "        xgb_learning_rate = position[4]\n",
    "        rf_min_samples_split = int(position[5])\n",
    "        \n",
    "        # Define the base models\n",
    "        base_models = [\n",
    "            ('rf', RandomForestClassifier(\n",
    "                n_estimators=rf_n_estimators,\n",
    "                max_depth=rf_max_depth,\n",
    "                min_samples_split=rf_min_samples_split,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )),\n",
    "            ('xgb', xgb.XGBClassifier(\n",
    "                n_estimators=xgb_n_estimators,\n",
    "                max_depth=xgb_max_depth,\n",
    "                learning_rate=xgb_learning_rate,\n",
    "                random_state=42,\n",
    "                eval_metric='logloss',\n",
    "                n_jobs=-1,\n",
    "                verbosity=0\n",
    "            ))\n",
    "        ]\n",
    "        \n",
    "        # Define the meta-model\n",
    "        meta_model = LogisticRegression(max_iter=1000)\n",
    "        \n",
    "        # Create the stacking classifier\n",
    "        stacking_clf = StackingClassifier(\n",
    "            estimators=base_models,\n",
    "            final_estimator=meta_model,\n",
    "            cv=5,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Train and predict\n",
    "        stacking_clf.fit(X_train, y_train)\n",
    "        y_pred = stacking_clf.predict(X_test)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        return -accuracy  # Negative for minimization\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in evaluate_fitness: {e}\")\n",
    "        return 0  # Return worst fitness on error\n",
    "\n",
    "print(\"✓ evaluate_fitness() function defined\")\n",
    "\n",
    "def initialize_spider_monkeys(n_monkeys, bounds, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Initialize spider monkey population.\"\"\"\n",
    "    monkeys = []\n",
    "    print(\"Initializing spider monkeys...\")\n",
    "    for i in range(n_monkeys):\n",
    "        position = np.random.uniform(bounds[:, 0], bounds[:, 1])\n",
    "        fitness = evaluate_fitness(position, X_train, X_test, y_train, y_test)\n",
    "        monkeys.append(SpiderMonkey(position, fitness))\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"  Initialized {i + 1}/{n_monkeys} monkeys\")\n",
    "    return monkeys\n",
    "\n",
    "print(\"✓ initialize_spider_monkeys() function defined\")\n",
    "\n",
    "def update_position(monkey, global_best, local_best, bounds, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Update spider monkey position.\"\"\"\n",
    "    new_position = (\n",
    "        monkey.position + \n",
    "        np.random.uniform(-1, 1, size=bounds.shape[0]) * (local_best.position - monkey.position) +\n",
    "        np.random.uniform(-1, 1, size=bounds.shape[0]) * (global_best.position - monkey.position)\n",
    "    )\n",
    "    \n",
    "    new_position = np.clip(new_position, bounds[:, 0], bounds[:, 1])\n",
    "    new_fitness = evaluate_fitness(new_position, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    if new_fitness < monkey.fitness:\n",
    "        monkey.position = new_position\n",
    "        monkey.fitness = new_fitness\n",
    "\n",
    "print(\"✓ update_position() function defined\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ALL FUNCTIONS SUCCESSFULLY DEFINED!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nDefined functions:\")\n",
    "print(\"  1. SpiderMonkey (class)\")\n",
    "print(\"  2. evaluate_fitness()\")\n",
    "print(\"  3. initialize_spider_monkeys()\")\n",
    "print(\"  4. update_position()\")\n",
    "print(\"\\nYou can now proceed to Cell 7 for testing!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d968d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing single fitness evaluation...\n",
      "--------------------------------------------------------------------------------\n",
      "Test hyperparameters:\n",
      "  RF: n_estimators=50, max_depth=10, min_samples_split=10\n",
      "  XGB: n_estimators=50, max_depth=5, learning_rate=0.1000\n",
      "✗ Test evaluation failed: name 'evaluate_fitness' is not defined\n",
      "\n",
      "Full error traceback:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/jg/v0bbfb4d6z31kv3sqwt32tr40000gn/T/ipykernel_19425/3405926086.py\", line 17, in <module>\n",
      "    test_fitness = evaluate_fitness(test_position, X_train, X_test, y_train, y_test)\n",
      "                   ^^^^^^^^^^^^^^^^\n",
      "NameError: name 'evaluate_fitness' is not defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 7: TEST SINGLE EVALUATION (SANITY CHECK)\n",
    "# ============================================================================\n",
    "# Test if a single fitness evaluation works\n",
    "\n",
    "print(\"\\nTesting single fitness evaluation...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Create a random position\n",
    "test_position = np.array([50, 10, 50, 5, 0.1, 10])\n",
    "\n",
    "print(f\"Test hyperparameters:\")\n",
    "print(f\"  RF: n_estimators={int(test_position[0])}, max_depth={int(test_position[1])}, min_samples_split={int(test_position[5])}\")\n",
    "print(f\"  XGB: n_estimators={int(test_position[2])}, max_depth={int(test_position[3])}, learning_rate={test_position[4]:.4f}\")\n",
    "\n",
    "try:\n",
    "    test_fitness = evaluate_fitness(test_position, X_train, X_test, y_train, y_test)\n",
    "    test_accuracy = -test_fitness\n",
    "    print(f\"\\n✓ Test evaluation successful!\")\n",
    "    print(f\"  - Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(\"\\nIf you see this message, your functions are working correctly!\")\n",
    "    print(\"You can proceed to Cell 8 to run the full optimization.\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Test evaluation failed: {e}\")\n",
    "    import traceback\n",
    "    print(\"\\nFull error traceback:\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d7ed280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING SPIDER MONKEY OPTIMIZATION\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'initialize_spider_monkeys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Initialize population\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m monkeys = \u001b[43minitialize_spider_monkeys\u001b[49m(N_MONKEYS, bounds, X_train, X_test, y_train, y_test)\n\u001b[32m     12\u001b[39m global_best = \u001b[38;5;28mmin\u001b[39m(monkeys, key=\u001b[38;5;28;01mlambda\u001b[39;00m monkey: monkey.fitness)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✓ Initial best accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m-global_best.fitness\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'initialize_spider_monkeys' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 8: RUN SPIDER MONKEY OPTIMIZATION\n",
    "# ============================================================================\n",
    "# Main optimization loop\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STARTING SPIDER MONKEY OPTIMIZATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Initialize population\n",
    "monkeys = initialize_spider_monkeys(N_MONKEYS, bounds, X_train, X_test, y_train, y_test)\n",
    "global_best = min(monkeys, key=lambda monkey: monkey.fitness)\n",
    "\n",
    "print(f\"\\n✓ Initial best accuracy: {-global_best.fitness:.4f}\")\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Main optimization loop\n",
    "print(\"\\nOptimization progress:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for iteration in range(N_ITERATIONS):\n",
    "    # Find local best\n",
    "    local_best = min(monkeys, key=lambda monkey: monkey.fitness)\n",
    "    \n",
    "    # Update all monkeys\n",
    "    for monkey in monkeys:\n",
    "        update_position(monkey, global_best, local_best, bounds, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # Update global best\n",
    "    current_best = min(monkeys, key=lambda monkey: monkey.fitness)\n",
    "    if current_best.fitness < global_best.fitness:\n",
    "        global_best = current_best\n",
    "    \n",
    "    # Track accuracy\n",
    "    current_accuracy = -global_best.fitness\n",
    "    accuracies.append(current_accuracy)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f'Iteration {iteration + 1:3d}/{N_ITERATIONS}: Best Accuracy = {current_accuracy:.4f}')\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f\"✓ Optimization complete!\")\n",
    "\n",
    "best_position = global_best.position\n",
    "best_fitness = -global_best.fitness\n",
    "\n",
    "print(f\"\\nBEST HYPERPARAMETERS FOUND:\")\n",
    "print(f\"  Random Forest:\")\n",
    "print(f\"    - n_estimators: {int(best_position[0])}\")\n",
    "print(f\"    - max_depth: {int(best_position[1])}\")\n",
    "print(f\"    - min_samples_split: {int(best_position[5])}\")\n",
    "print(f\"  XGBoost:\")\n",
    "print(f\"    - n_estimators: {int(best_position[2])}\")\n",
    "print(f\"    - max_depth: {int(best_position[3])}\")\n",
    "print(f\"    - learning_rate: {best_position[4]:.4f}\")\n",
    "print(f\"\\nBest Accuracy: {best_fitness:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0232d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 9: PLOT ACCURACY OVER ITERATIONS\n",
    "# ============================================================================\n",
    "# Visualize optimization progress\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, N_ITERATIONS + 1), accuracies, marker='o', \n",
    "         linestyle='-', color='blue', linewidth=2, markersize=6)\n",
    "plt.title('Accuracy over Iterations during SMO', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Iteration', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Accuracy plot displayed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c3eaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 10: TRAIN FINAL MODEL WITH BEST HYPERPARAMETERS\n",
    "# ============================================================================\n",
    "# Retrain the model with optimized hyperparameters\n",
    "\n",
    "print(\"\\nRetraining model with best hyperparameters...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Create models with best hyperparameters\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=int(best_position[0]),\n",
    "        max_depth=int(best_position[1]),\n",
    "        min_samples_split=int(best_position[5]),\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "    ('xgb', xgb.XGBClassifier(\n",
    "        n_estimators=int(best_position[2]),\n",
    "        max_depth=int(best_position[3]),\n",
    "        learning_rate=best_position[4],\n",
    "        random_state=42,\n",
    "        eval_metric='logloss',\n",
    "        n_jobs=-1,\n",
    "        verbosity=0\n",
    "    ))\n",
    "]\n",
    "\n",
    "meta_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the final model\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "y_pred_proba = stacking_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"✓ Final model trained!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3fa978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 11: CALCULATE ALL METRICS\n",
    "# ============================================================================\n",
    "# Compute and display all evaluation metrics\n",
    "\n",
    "print(\"\\nFINAL MODEL EVALUATION METRICS:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate metrics\n",
    "final_accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy:  {final_accuracy:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09fcd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 12: PLOT CONFUSION MATRIX\n",
    "# ============================================================================\n",
    "# Visualize the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Disease', 'Disease'])\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Confusion matrix displayed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf67c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 13: PLOT ROC CURVE\n",
    "# ============================================================================\n",
    "# Visualize the ROC curve\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc_val = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc_val:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='grey', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=16, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\", fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ ROC curve displayed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47faa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 14: SUMMARY AND FINAL OUTPUT\n",
    "# ============================================================================\n",
    "# Display final summary\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXECUTION COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nSUMMARY:\")\n",
    "print(f\"  Dataset: {DATA_PATH}\")\n",
    "print(f\"  Total samples: {len(X)}\")\n",
    "print(f\"  Training samples: {len(X_train)}\")\n",
    "print(f\"  Test samples: {len(X_test)}\")\n",
    "print(f\"  Features: {X_train.shape[1]}\")\n",
    "print(f\"\\n  SMO Iterations: {N_ITERATIONS}\")\n",
    "print(f\"  Population Size: {N_MONKEYS}\")\n",
    "print(f\"\\n  Final Test Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"  F1 Score: {f1:.4f}\")\n",
    "print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
